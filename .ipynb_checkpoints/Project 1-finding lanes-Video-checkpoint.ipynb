{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "# Import everything neede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color   \n",
    "    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "\n",
    "def average_slope_intercept(image, lines):\n",
    "    \"\"\"This function calculate the average lines from left and right part of the image, \n",
    "    this let us use the average line parameter to draw only two lines that mark the lanes, \n",
    "    even if it isn't continous\"\"\"\n",
    "    \n",
    "    left_fit = []\n",
    "    right_fit = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 =line.reshape(4)\n",
    "        param = np.polyfit((x1, x2),(y1, y2),1)\n",
    "        slope = param[0]\n",
    "        intercept = param[1]\n",
    "        if slope > 0:\n",
    "            if slope > 0.4:\n",
    "                right_fit.append((slope, intercept))\n",
    "        else:\n",
    "            if slope < (-0.4):\n",
    "                left_fit.append((slope, intercept))\n",
    "            \n",
    "    left_average = np.average(left_fit,axis=0)\n",
    "    right_average = np.average(right_fit,axis=0)\n",
    "    left_line = make_coordinates(image, left_average)\n",
    "    right_line = make_coordinates(image, right_average)\n",
    "    return np.array([left_line, right_line])\n",
    "\n",
    "def make_coordinates (image, line_parameters):\n",
    "    \"\"\"I added an exception to avoid a problem with the slope in some frames\"\"\" \n",
    "    try:\n",
    "        slope, intercept = line_parameters\n",
    "        y1 = image.shape[0]\n",
    "        y2 = int(y1*(65/100))\n",
    "        x1 = int((y1-intercept)/slope)\n",
    "        x2 = int((y2-intercept)/slope)\n",
    "    \n",
    "    except TypeError:\n",
    "        slope, intercept = 0,0\n",
    "        y1 = 0\n",
    "        y2 = 0\n",
    "        x1 = 0\n",
    "        x2 = 0\n",
    "    return np.array([x1, y1, x2, y2])\n",
    "  \n",
    "\n",
    "def display_lines(image, lines):\n",
    "    \"\"\"This function draw the lines over an image \"\"\"\n",
    "    line_image= np.zeros_like(image)\n",
    "    if lines is not None:\n",
    "        for x1,y1,x2,y2 in lines:\n",
    "            cv2.line(line_image, (x1,y1),(x2,y2),(0,255,0), 10)\n",
    "    return line_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "#I had an issue that i solved running in anaconda prompt \"pip install moviepy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "        #STEP 1 Grayscale\n",
    "        gray=cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        #STEP 2 Gaussian Blur\n",
    "        kernel_size=5\n",
    "        gray=cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
    "       \n",
    "        #STEP 3 Canny Image\n",
    "        low_threshold=50\n",
    "        high_threshold=150\n",
    "        Canny=cv2.Canny(gray, low_threshold, high_threshold)\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        \n",
    "        #STEP 4 Mask Image\n",
    "        vertices = np.array([[(width*.15,height),(width*.95, height), (width*.5,height*(1/2))]],dtype='int')\n",
    "        masked_image=region_of_interest(Canny, vertices)\n",
    "          \n",
    "        #STEP 5 Detect lines    \n",
    "        lines = cv2.HoughLinesP(masked_image, 1, np.pi/180, 50, np.array([]), 10, 1)\n",
    "       \n",
    "        #STEP 6 Average lines and slope filter\n",
    "        average_lines = average_slope_intercept(masked_image, lines)\n",
    "        \n",
    "        #STEP 7 Display images\n",
    "        line_image=display_lines(image, average_lines)\n",
    "        \n",
    "        #STEP 8 Mix original image with lines\n",
    "        weighted = cv2.addWeighted(image,0.8,line_image, 1, 1)\n",
    "        result=weighted\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|▉                                                                    | 3/221 [00:00<00:07, 29.84it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidWhiteRight.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidWhiteRight.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidWhiteRight.mp4\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|▍                                                                    | 4/681 [00:00<00:18, 37.60it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidYellowLeft.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidYellowLeft.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidYellowLeft.mp4\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|▌                                                                    | 2/251 [00:00<00:15, 15.64it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/challenge.mp4.\n",
      "Moviepy - Writing video test_videos_output/challenge.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/challenge.mp4\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "#clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
